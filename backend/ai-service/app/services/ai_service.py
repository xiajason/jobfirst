"""
JobFirst AIæœåŠ¡æ ¸å¿ƒç±»
é›†æˆå¤šç§AIæ¨¡å‹ï¼Œæä¾›ç®€å†åˆ†æã€ä¼˜åŒ–ç­‰åŠŸèƒ½
"""

import asyncio
import logging
import json
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
from dataclasses import dataclass

import openai
from anthropic import AsyncAnthropic
import numpy as np
from pydantic import BaseModel, ValidationError

from app.config import config
from app.models.resume import ResumeContent, ResumeAnalysisResult
from app.models.analysis import AnalysisRequest, OptimizationRequest
from app.utils.logger import get_logger
from app.utils.cache import AsyncCache

logger = get_logger(__name__)


@dataclass
class AIModelConfig:
    """AIæ¨¡å‹é…ç½®"""
    name: str
    provider: str
    max_tokens: int
    temperature: float
    timeout: int
    cost_per_1k_tokens: float


class AIService:
    """AIæœåŠ¡ä¸»ç±»"""
    
    def __init__(self):
        self.openai_client: Optional[openai.AsyncOpenAI] = None
        self.anthropic_client: Optional[AsyncAnthropic] = None
        self.cache = AsyncCache()
        self.health_status = "initializing"
        self.model_configs = self._init_model_configs()
        
    async def initialize(self):
        """åˆå§‹åŒ–AIæœåŠ¡"""
        try:
            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
            if config.ai.OPENAI_API_KEY:
                self.openai_client = openai.AsyncOpenAI(
                    api_key=config.ai.OPENAI_API_KEY,
                    timeout=config.ai.ANALYSIS_TIMEOUT
                )
                logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯
            if config.ai.ANTHROPIC_API_KEY:
                self.anthropic_client = AsyncAnthropic(
                    api_key=config.ai.ANTHROPIC_API_KEY,
                    timeout=config.ai.ANALYSIS_TIMEOUT
                )
                logger.info("âœ… Anthropicå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # éªŒè¯æ¨¡å‹å¯ç”¨æ€§
            await self._validate_models()
            
            self.health_status = "healthy"
            logger.info("ğŸ‰ AIæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.health_status = "error"
            logger.error(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.openai_client:
                await self.openai_client.close()
            if self.anthropic_client:
                await self.anthropic_client.close()
            logger.info("âœ… AIæœåŠ¡èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ AIæœåŠ¡èµ„æºæ¸…ç†å¤±è´¥: {e}")
    
    def is_healthy(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        return self.health_status == "healthy"
    
    def _init_model_configs(self) -> Dict[str, AIModelConfig]:
        """åˆå§‹åŒ–æ¨¡å‹é…ç½®"""
        return {
            "gpt-4": AIModelConfig(
                name="gpt-4",
                provider="openai",
                max_tokens=config.ai.OPENAI_MAX_TOKENS,
                temperature=config.ai.OPENAI_TEMPERATURE,
                timeout=config.ai.ANALYSIS_TIMEOUT,
                cost_per_1k_tokens=0.03
            ),
            "gpt-3.5-turbo": AIModelConfig(
                name="gpt-3.5-turbo",
                provider="openai",
                max_tokens=config.ai.OPENAI_MAX_TOKENS,
                temperature=config.ai.OPENAI_TEMPERATURE,
                timeout=config.ai.ANALYSIS_TIMEOUT,
                cost_per_1k_tokens=0.002
            ),
            "claude-3-sonnet": AIModelConfig(
                name="claude-3-sonnet-20240229",
                provider="anthropic",
                max_tokens=config.ai.OPENAI_MAX_TOKENS,
                temperature=config.ai.OPENAI_TEMPERATURE,
                timeout=config.ai.ANALYSIS_TIMEOUT,
                cost_per_1k_tokens=0.015
            ),
            "claude-3-haiku": AIModelConfig(
                name="claude-3-haiku-20240307",
                provider="anthropic",
                max_tokens=config.ai.OPENAI_MAX_TOKENS,
                temperature=config.ai.OPENAI_TEMPERATURE,
                timeout=config.ai.ANALYSIS_TIMEOUT,
                cost_per_1k_tokens=0.00025
            )
        }
    
    async def _validate_models(self):
        """éªŒè¯æ¨¡å‹å¯ç”¨æ€§"""
        validation_tasks = []
        
        if self.openai_client:
            validation_tasks.append(self._validate_openai())
        
        if self.anthropic_client:
            validation_tasks.append(self._validate_anthropic())
        
        if validation_tasks:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception):
                    logger.warning(f"âš ï¸ æ¨¡å‹éªŒè¯å¤±è´¥: {result}")
    
    async def _validate_openai(self):
        """éªŒè¯OpenAIæ¨¡å‹"""
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            logger.info(f"âœ… OpenAIæ¨¡å‹éªŒè¯æˆåŠŸ: {response.choices[0].message.content}")
        except Exception as e:
            logger.error(f"âŒ OpenAIæ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            raise
    
    async def _validate_anthropic(self):
        """éªŒè¯Anthropicæ¨¡å‹"""
        try:
            response = await self.anthropic_client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=10,
                messages=[{"role": "user", "content": "Hello"}]
            )
            logger.info(f"âœ… Anthropicæ¨¡å‹éªŒè¯æˆåŠŸ: {response.content[0].text}")
        except Exception as e:
            logger.error(f"âŒ Anthropicæ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            raise
    
    async def analyze_resume(
        self,
        resume_content: ResumeContent,
        analysis_request: AnalysisRequest
    ) -> ResumeAnalysisResult:
        """åˆ†æç®€å†"""
        cache_key = f"resume_analysis:{hash(str(resume_content))}:{hash(str(analysis_request))}"
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            logger.info("ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ç®€å†åˆ†æç»“æœ")
            return ResumeAnalysisResult(**cached_result)
        
        try:
            # é€‰æ‹©AIæ¨¡å‹
            model_config = self._select_model(analysis_request.analysis_type)
            
            # æ„å»ºåˆ†ææç¤º
            prompt = self._build_analysis_prompt(resume_content, analysis_request)
            
            # è°ƒç”¨AIæ¨¡å‹
            analysis_result = await self._call_ai_model(
                prompt=prompt,
                model_config=model_config,
                task_type="resume_analysis"
            )
            
            # è§£æAIå“åº”
            parsed_result = self._parse_analysis_response(analysis_result, resume_content)
            
            # ç¼“å­˜ç»“æœ
            await self.cache.set(cache_key, parsed_result.dict(), ttl=3600)  # 1å°æ—¶ç¼“å­˜
            
            logger.info(f"âœ… ç®€å†åˆ†æå®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model_config.name}")
            return parsed_result
            
        except Exception as e:
            logger.error(f"âŒ ç®€å†åˆ†æå¤±è´¥: {e}")
            raise
    
    async def optimize_resume(
        self,
        resume_content: ResumeContent,
        analysis_result: ResumeAnalysisResult,
        optimization_request: OptimizationRequest
    ) -> Dict[str, Any]:
        """ä¼˜åŒ–ç®€å†"""
        try:
            # æ„å»ºä¼˜åŒ–æç¤º
            prompt = self._build_optimization_prompt(
                resume_content, 
                analysis_result, 
                optimization_request
            )
            
            # é€‰æ‹©ä¼˜åŒ–æ¨¡å‹
            model_config = self._select_model("comprehensive")
            
            # è°ƒç”¨AIæ¨¡å‹
            optimization_result = await self._call_ai_model(
                prompt=prompt,
                model_config=model_config,
                task_type="resume_optimization"
            )
            
            # è§£æä¼˜åŒ–ç»“æœ
            parsed_result = self._parse_optimization_response(optimization_result)
            
            logger.info(f"âœ… ç®€å†ä¼˜åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model_config.name}")
            return parsed_result
            
        except Exception as e:
            logger.error(f"âŒ ç®€å†ä¼˜åŒ–å¤±è´¥: {e}")
            raise
    
    async def generate_embeddings(
        self,
        text: str,
        model: str = "text-embedding-ada-002"
    ) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬å‘é‡åµŒå…¥"""
        try:
            if not self.openai_client:
                raise ValueError("OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            
            response = await self.openai_client.embeddings.create(
                input=text,
                model=model
            )
            
            embeddings = response.data[0].embedding
            logger.info(f"âœ… ç”Ÿæˆå‘é‡åµŒå…¥æˆåŠŸï¼Œç»´åº¦: {len(embeddings)}")
            return embeddings
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå‘é‡åµŒå…¥å¤±è´¥: {e}")
            raise
    
    def _select_model(self, analysis_type: str) -> AIModelConfig:
        """é€‰æ‹©AIæ¨¡å‹"""
        if analysis_type == "basic":
            return self.model_configs["gpt-3.5-turbo"]
        elif analysis_type == "comprehensive":
            return self.model_configs["gpt-4"]
        elif analysis_type == "expert":
            return self.model_configs["claude-3-sonnet"]
        else:
            return self.model_configs["gpt-4"]
    
    def _build_analysis_prompt(
        self,
        resume_content: ResumeContent,
        analysis_request: AnalysisRequest
    ) -> str:
        """æ„å»ºç®€å†åˆ†ææç¤º"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç®€å†ï¼Œå¹¶æä¾›ä¸“ä¸šçš„è¯„ä¼°å’Œå»ºè®®ã€‚

ç®€å†å†…å®¹ï¼š
å§“åï¼š{resume_content.personal_info.name}
èŒä½ï¼š{resume_content.personal_info.title or 'æœªæŒ‡å®š'}
ç»éªŒï¼š{len(resume_content.experience)}å¹´å·¥ä½œç»éªŒ
æŠ€èƒ½ï¼š{', '.join(resume_content.skills)}

è¯¦ç»†å†…å®¹ï¼š
{json.dumps(resume_content.dict(), ensure_ascii=False, indent=2)}

åˆ†æè¦æ±‚ï¼š
- åˆ†æç±»å‹ï¼š{analysis_request.analysis_type}
- ç›®æ ‡èŒä½ï¼š{analysis_request.target_job or 'æœªæŒ‡å®š'}
- è¡Œä¸šï¼š{analysis_request.industry or 'æœªæŒ‡å®š'}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. æ•´ä½“è¯„åˆ†ï¼ˆ0-100ï¼‰
2. å†…å®¹è¯„åˆ†ï¼ˆ0-100ï¼‰
3. æ ¼å¼è¯„åˆ†ï¼ˆ0-100ï¼‰
4. ç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-100ï¼‰
5. ä¼˜åŠ¿åˆ†æ
6. æ”¹è¿›å»ºè®®
7. æŠ€èƒ½åˆ†æ
8. ç»éªŒåˆ†æ
9. å¸‚åœºåˆ†æ

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
"""
        return prompt
    
    def _build_optimization_prompt(
        self,
        resume_content: ResumeContent,
        analysis_result: ResumeAnalysisResult,
        optimization_request: OptimizationRequest
    ) -> str:
        """æ„å»ºç®€å†ä¼˜åŒ–æç¤º"""
        prompt = f"""
åŸºäºä»¥ä¸‹ç®€å†åˆ†æç»“æœï¼Œè¯·æä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®å’Œæ”¹è¿›åçš„ç®€å†å†…å®¹ã€‚

åŸå§‹ç®€å†ï¼š
{json.dumps(resume_content.dict(), ensure_ascii=False, indent=2)}

åˆ†æç»“æœï¼š
{json.dumps(analysis_result.dict(), ensure_ascii=False, indent=2)}

ä¼˜åŒ–è¦æ±‚ï¼š
- ä¼˜åŒ–é‡ç‚¹ï¼š{optimization_request.optimization_focus}
- ç›®æ ‡èŒä½ï¼š{optimization_request.target_job or 'æœªæŒ‡å®š'}
- è¡Œä¸šï¼š{optimization_request.industry or 'æœªæŒ‡å®š'}

è¯·æä¾›ï¼š
1. ä¼˜åŒ–åçš„ç®€å†å†…å®¹
2. å…·ä½“çš„ä¿®æ”¹è¯´æ˜
3. å…³é”®è¯ä¼˜åŒ–å»ºè®®
4. æ ¼å¼æ”¹è¿›å»ºè®®
5. ä¼˜åŒ–æ•ˆæœè¯„ä¼°

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
"""
        return prompt
    
    async def _call_ai_model(
        self,
        prompt: str,
        model_config: AIModelConfig,
        task_type: str
    ) -> str:
        """è°ƒç”¨AIæ¨¡å‹"""
        try:
            if model_config.provider == "openai" and self.openai_client:
                return await self._call_openai(prompt, model_config)
            elif model_config.provider == "anthropic" and self.anthropic_client:
                return await self._call_anthropic(prompt, model_config)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {model_config.provider}")
                
        except Exception as e:
            logger.error(f"âŒ AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    async def _call_openai(self, prompt: str, model_config: AIModelConfig) -> str:
        """è°ƒç”¨OpenAIæ¨¡å‹"""
        response = await self.openai_client.chat.completions.create(
            model=model_config.name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=model_config.max_tokens,
            temperature=model_config.temperature
        )
        return response.choices[0].message.content
    
    async def _call_anthropic(self, prompt: str, model_config: AIModelConfig) -> str:
        """è°ƒç”¨Anthropicæ¨¡å‹"""
        response = await self.anthropic_client.messages.create(
            model=model_config.name,
            max_tokens=model_config.max_tokens,
            temperature=model_config.temperature,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text
    
    def _parse_analysis_response(self, ai_response: str, resume_content: ResumeContent) -> ResumeAnalysisResult:
        """è§£æAIåˆ†æå“åº”"""
        try:
            # å°è¯•è§£æJSONå“åº”
            if ai_response.strip().startswith('{'):
                parsed_data = json.loads(ai_response)
            else:
                # å¦‚æœä¸æ˜¯JSONï¼Œå°è¯•æå–å…³é”®ä¿¡æ¯
                parsed_data = self._extract_analysis_from_text(ai_response)
            
            # æ„å»ºåˆ†æç»“æœ
            analysis_result = ResumeAnalysisResult(
                analysis_id=f"analysis_{datetime.now().timestamp()}",
                resume_id=resume_content.personal_info.name,  # ä¸´æ—¶ID
                analysis_time=datetime.now().isoformat(),
                analysis_type="comprehensive",
                overall_score=parsed_data.get('overall_score', 75),
                content_score=parsed_data.get('content_score', 75),
                format_score=parsed_data.get('format_score', 75),
                relevance_score=parsed_data.get('relevance_score', 75),
                strengths=parsed_data.get('strengths', []),
                weaknesses=parsed_data.get('weaknesses', []),
                suggestions=parsed_data.get('suggestions', []),
                skill_analysis=parsed_data.get('skill_analysis', {}),
                experience_analysis=parsed_data.get('experience_analysis', {}),
                market_analysis=parsed_data.get('market_analysis', {})
            )
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ è§£æAIåˆ†æå“åº”å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return self._create_default_analysis_result(resume_content)
    
    def _parse_optimization_response(self, ai_response: str) -> Dict[str, Any]:
        """è§£æAIä¼˜åŒ–å“åº”"""
        try:
            if ai_response.strip().startswith('{'):
                return json.loads(ai_response)
            else:
                return {"message": "ä¼˜åŒ–å®Œæˆ", "details": ai_response}
        except Exception as e:
            logger.error(f"âŒ è§£æAIä¼˜åŒ–å“åº”å¤±è´¥: {e}")
            return {"error": "è§£æä¼˜åŒ–ç»“æœå¤±è´¥"}
    
    def _extract_analysis_from_text(self, text: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–åˆ†æä¿¡æ¯"""
        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘
        result = {
            'overall_score': 75,
            'content_score': 75,
            'format_score': 75,
            'relevance_score': 75,
            'strengths': [],
            'weaknesses': [],
            'suggestions': []
        }
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„æ–‡æœ¬è§£æé€»è¾‘
        return result
    
    def _create_default_analysis_result(self, resume_content: ResumeContent) -> ResumeAnalysisResult:
        """åˆ›å»ºé»˜è®¤åˆ†æç»“æœ"""
        return ResumeAnalysisResult(
            analysis_id=f"analysis_{datetime.now().timestamp()}",
            resume_id=resume_content.personal_info.name,
            analysis_time=datetime.now().isoformat(),
            analysis_type="basic",
            overall_score=70,
            content_score=70,
            format_score=70,
            relevance_score=70,
            strengths=["ç®€å†ç»“æ„æ¸…æ™°", "åŒ…å«åŸºæœ¬ä¿¡æ¯"],
            weaknesses=["éœ€è¦æ›´å¤šå…·ä½“æˆå°±æè¿°", "æŠ€èƒ½æè¿°å¯ä»¥æ›´è¯¦ç»†"],
            suggestions=[],
            skill_analysis={},
            experience_analysis={},
            market_analysis={}
        )
